global_config:
  force_download: false
  random_seed: 42
  corpus_dir: ./outputs/data
  output_dir: ./outputs/manifests
  storage_path: ./outputs/features
  sampling_rate: 8000

  features:
    feature_type: "mfcc"
    sampling_rate: 8000
    frame_length: 0.025         # 25 ms -> 200 samples @ 8kHz
    frame_shift: 0.01           # 80 samples @ 8kHz -> 0.01 s
    num_mel_bins: 40
    num_ceps: 40               # keep all cepstra (no reduction)
    use_energy: false
    low_freq: 40.0
    high_freq: 3700.0          # or -200.0 for Nyquist - 200
    snip_edges: false
    preemph_coeff: 0.97
    window_type: "povey"
    dither: 0.0
    round_to_power_of_two: true
    torchaudio_compatible_mel_scale: true
    norm_filters: false
    cepstral_lifter: 22
    num_jobs: 4
    storage_type: "lilcom_chunky"
    mix_eagerly: true
   
    dataloader:
      num_workers: 0             # if input_strategy.num_workers > 0, this is forced to 0
      pin_memory: true
      persistent_workers: false
      prefetch_factor: 2
  
  # Storage and computation
  storage_type: lilcom_chunky
  num_jobs: 1  # Use single process for reliable caching
  device: cpu
  progress_bar: true
  cut_window_seconds: 50  # Window long recordings before extraction

datasets:
  - name: ava_avd
    download_params:
      download_annotations: true
      download_videos: true

  - name: libriheavy_mix
    download_params:
      # Dataset splits to download
      # Options: small (~100h), medium (~900h), large (~9000h), dev, test
      dataset_parts: small
      
      # Number of speakers per mixture
      # Options: 1, 2, 3, 4 (can be int or list)
      speaker_counts: [1, 2, 3, 4]
      
      # HuggingFace cache directory
      cache_dir: null
    
    process_params:
      # Dataset splits to process
      dataset_parts: small

      # Speaker counts to process
      speaker_counts: [1, 2, 3, 4]
      
      # Speaker filtering
      min_speakers: 1
      max_speakers: 4
      
      # Custom split mapping (optional)
      splits: null

  - name: ami
    download_params:
      # Microphone type: ihm (individual headset), sdm (single distant), mdm (multiple distant)
      mic: ihm-mix
      url: http://groups.inf.ed.ac.uk/ami
      annotations: null  # Auto-downloaded
    
    process_params:
      # Microphone type to process (must match download)
      mic: ihm-mix
      
      # Partition selection
      # Options: full-corpus, full-corpus-asr, scenario-only
      partition: full-corpus
      
      # Text normalization
      # Options: none, upper, kaldi
      normalize_text: none
      
      # Segmentation options
      max_words_per_segment: null  # null = no splitting
      merge_consecutive: false  # Merge same-speaker consecutive segments

  - name: icsi
    download_params:
      # Microphone type: ihm (individual headset), mdm (multiple distant)
      mic: ihm-mix
      url: http://groups.inf.ed.ac.uk/ami
      transcripts_dir: ./outputs/data/icsi/ICSI

    process_params:
      # Microphone type to process
      mic: ihm-mix
      
      # Text normalization
      # Options: none, upper, kaldi
      normalize_text: none
      
      # Audio format conversion
      save_to_wav: true  # Convert SPH files to WAV if needed
      output_dir: ./outputs/manifests/icsi
      audio_dir: ./outputs/data/icsi/speech
      transcripts_dir: ./outputs/data/icsi/ICSI

  - name: aishell4
    download_params:
      # Base URL for downloads
      base_url: http://www.openslr.org/resources
    
    process_params:
      # Chinese text normalization
      normalize_text: false  # Set true to normalize Chinese characters

  - name: voxconverse
    download_params:
      corpus_dir: null  # Will use global_config corpus_dir/voxconverse
    
    process_params:
      split_test: false  # Whether to split test set


  # - name: ego4d
  #   download_params:
  #     # Dataset parts to download
  #     # Options: clips, annotations, metadata, takes, captures, etc.
  #     dataset_parts: ["clips", "annotations"]
      
  #     # Auto-install Ego4D CLI if not available
  #     install_cli: true
      
  #     # Download timeout (seconds)
  #     timeout: 3600
      
  #     # Path to .env file for environment variables
  #     env_file: ./.env  # Load AWS credentials from project .env file
    
  #   process_params:
  #     # Audio extraction settings
  #     extract_audio: true
  #     audio_sample_rate: 16000
      
  #     # Segment duration constraints
  #     min_segment_duration: 0.5  # seconds
  #     max_segment_duration: 30.0  # seconds
      
  #     # Limit number of clips for testing (0 = no limit)
  #     max_clips: 0
      
  #     # Filter annotations by type (e.g., "av" for audio-visual)
  #     annotation_subset: "av"  # null = all annotations

  # - name: mswild
  #   download_params:
  #     # Multi-modal data downloads
  #     download_audio: true  # ~7.56 GB (required)
  #     download_video: false  # ~43.14 GB (manual download required)
  #     download_faces: false  # ~14.49 GB (manual download required)

    # process_params:
    #   # Split name to RTTM pattern mapping
    #   # Default: {"train": "few_train", "dev": "few_val", "test": "many_val"}
    #   splits:
    #     train: few_train
    #     dev: few_val
    #     test: many_val


  # - name: voxceleb1
  #   download_params: {}
    
  #   # Note: VoxCeleb processing combines voxceleb1 and voxceleb2
  #   # Use voxceleb1_root in process_params
  #   process_params: {}

  # - name: voxceleb2
  #   download_params: {}
    
  #   # Note: VoxCeleb processing combines voxceleb1 and voxceleb2
  #   # Use voxceleb2_root in process_params
  #   process_params: {}

  # - name: tedlium
  #   download_params: {}
    
  #   process_params:
  #     # TED-LIUM root directory
  #     tedlium_root: null
      
  #     # Dataset parts to process
  #     # Options: null (auto-detect), or specific parts
  #     dataset_parts: null
      
  #     # Text normalization
  #     # Options: none, upper, lower, kaldi
  #     normalize_text: none

  # - name: libricss
  #   download_params: {}
    
  #   process_params:
  #     # Recording type
  #     # Options: mdm (multiple distant microphone)
  #     type: ihm-mix
      
  #     # Generate segmented cuts
  #     segmented_cuts: false
      
  # - name: chime6
  #   download_params: {}
    
  #   process_params:
  #     # Dataset parts to process
  #     # Options: all, train, dev, eval
  #     dataset_parts: all
      
  #     # Microphone type: mdm (multiple distant microphone)
  #     mic: ihm-mix
      
  #     # Use reference array
  #     use_reference_array: false
      
  #     # Perform array synchronization
  #     perform_array_sync: false
      
  #     # Verify MD5 checksums
  #     verify_md5_checksums: false
      
  #     # Number of threads per job
  #     num_threads_per_job: 1
      
  #     # Path to sox binary
  #     sox_path: /usr/bin/sox
      
  #     # Text normalization
  #     normalize_text: null
      
  #     # Use CHiME-7 split
  #     use_chime7_split: false