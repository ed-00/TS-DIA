**LibriheavyMix**  
    Jin, X., Zhang, Y., Wei, S., et al. “LibriheavyMix: A 20,000-Hour Dataset for Single-Channel Overlapped Speech Separation and Diarization.” *Interspeech 2024*.  
    https://arxiv.org/abs/2409.00819  

---

**1. Dataset Overview**  
a. **Total Size:**

- "_This work releases a large-scale (20,000 hours) synthesized corpus for overlapped speech separation and recognition under reverberant conditions_"
    
- "_LibriheavyMix presents...10,000 hours (single version), training data is split into small (100h), medium (900h) and large (9,000h) sets_"  
    b. **Domains & Scenarios:**
    
- "_The evolving speech processing landscape is increasingly focused on complex scenarios like meetings or cocktail parties with multiple simultaneous speakers and far-field conditions._"
    
- "_Conference scenario dataset with human-annotated segmentation (AliMeeting)_"
    
- "_Mixtures are generated by randomly selecting utterances for different speakers_"
    

**2. Recording Conditions**  
a. **Audio Quality:**

- "_Anechoic single channel training samples... Reverberation was also introduced using FAST-RIR...to extend to a more challenging reverberant scenario._"
    
- "_An SNR value randomly selected within [−5, 5] is assigned to utterances of each speaker._"  
    b. **Microphone Configurations:**
    
- "_Single channel far-field...do not require specific information about microphone arrays_"
    

**3. Speaker & Language Characteristics**  
a. **Speakers per Recording:**

- "_Each training set...includes conversations involving 1–4 speakers_"
    
- "_The variety of speakers is much wider...with around 6,000 distinct speakers in the large training set_"  
    b. **Languages Represented:**
    
- "_Source utterances are from the Libriheavy dataset, which is an ASR corpus..._" _(Libriheavy is based on English audiobooks.)_
    

**4. Annotations & Metadata**  
a. **Annotation Types:**

- "_Speaker identity and corresponding timestamps for further investigation_"  
    b. **Annotation Format:**
    
- _Not explicitly specified; based on Libriheavy, likely format includes JSON, text with timestamps_  
    c. **Forced-alignment, Transcript Segmentation:**
    
- "_Utterances with duration >15 seconds are first aligned using wav2vec2.0 to obtain boundaries of sub-utterances for mixture simulation_"
    

**5. Licensing & Access**  
a. **Licensing Model:**

- _Not explicitly stated in the main text, but dataset is released via Huggingface, implying open access under community guidelines_  
    b. **Download Links:**
    
- "_[https://huggingface.co/datasets/zrjin/LibriheavyMix-{dev,test,small,medium,large}](https://huggingface.co/datasets/zrjin/LibriheavyMix-%7Bdev,test,small,medium,large%7D)_"
    

**6. Data Splits & Benchmarks**  
a. **Training/Dev/Test Splits:**

- "_Each training set of LibriheavyMix uniformly includes conversations involving 1-4 speakers, noted as small{1-4}spk, medium{1-4}spk and large{1-4}spk. For the dev and test sets, mixtures containing 2 to 4 speakers are derived from the dev, test-clean and test-other sets of the original Libriheavy corpus, noted as dev{2-4}spk, test-clean{2-4}spk and test-other{2-4}spk._"  
    b. **Evaluation Metrics:**
    
- "_DER (Diarization Error Rate), cpWER (concatenated minimum-permutation Word Error Rate), SI-SNR (Scale-invariant signal-to-noise ratio)_"  
    c. **Baseline Results Published:**
    
- Detailed tables include:
    
    - "_Word error rate (%) of AED model_"
        
    - "_Performance of the Conv-TasNet model on LibriheavyMix and WHAMR! dataset_"
        
    - "_Performance of the pyannote.audio diarization system (DER: e.g., 19.68% for best pipeline)_"
        

**7. Usage & Preprocessing**  
a. **Preprocessing Steps:**

- "_Speed perturbation is further applied except for the ones with large{1-4}spk training set involved._"
    
- "_SpecAugment is incorporated for all systems._"  
    b. **Existing Toolkits/Scripts:**
    
- "_ESPnet toolkit used for ASR (see tuning/train_sot_asr_conformer.yaml of ESPnet)_"
    

**8. Challenges & Limitations**  
a. **Known Challenges:**

- "_Scaling up the amount of training data demonstrates a significant reduction on cpWER and speaker counting accuracy...performance degradation on the most challenging 4-speaker scenario._"
    
- "_Conv-TasNet model trained on wsj0-2mix demonstrates poor generalization on other datasets._"  
    b. **Limitations:**
    
- "_It is difficult to obtain clean separation targets from real-world recorded data, limiting their capability as training data for speech separation models._"
    
- Licensing: _Not specified, but may be restricted by Huggingface terms or original Libriheavy._
    

**9. Research Applications**  
a. **Research Tasks Suited:**

- "_Decoding 'Who said What and When' in multitalker, reverberant environments_"
    
- "_Speech separation, recognition, and speaker diarization_"  
    b. **Notable Papers:**
    
- "_Further evaluation using a public benchmark for far-field overlapped speech separation and recognition validates the effectiveness and generalizability of the proposed dataset. References list studies employing similar approaches and datasets (,,,...)_"
    

**10. Reproducibility**  
a. **Reproducibility:**

- "_Simulation algorithms are specified (Algorithm 1, 2), scripts/configs available in ESPnet egs2/librimix/sot_asr1/"_  
    b. **Version Controls/Logs:**
    
- _Not mentioned in main text; dataset versions denoted in URLs (dev, test, small, medium, large)_
    

---

Quotations and details are directly sourced from the arXiv paper content. If you need citations for specific sections, let me know!

1. [https://arxiv.org/pdf/2409.00819.pdf](https://arxiv.org/pdf/2409.00819.pdf)